Iteration 0 loss 1.26234189167 train RMSE 2.59208276317 Validation RMSE 0 : 1.66797310965
Iteration 10 loss 0.544983809038 train RMSE 1.3010949567 Validation RMSE 10 : 0.833912687772
Iteration 20 loss 0.48479137675 train RMSE 1.16345352527 Validation RMSE 20 : 0.827720219274
Iteration 30 loss 0.434783626023 train RMSE 1.04179808106 Validation RMSE 30 : 0.865756047654
Iteration 40 loss 0.407308593099 train RMSE 0.954502392444 Validation RMSE 40 : 0.81824494429
Iteration 50 loss 0.412399804344 train RMSE 0.931377477689 Validation RMSE 50 : 0.896478158435
Iteration 60 loss 0.404511657276 train RMSE 0.914024352231 Validation RMSE 60 : 0.681533236638
Iteration 70 loss 0.408416400297 train RMSE 0.926782959415 Validation RMSE 70 : 0.770235078647
Iteration 80 loss 0.414914226831 train RMSE 0.897182882278 Validation RMSE 80 : 0.671672413469
Iteration 90 loss 0.407678568248 train RMSE 0.937010096657 Validation RMSE 90 : 0.719727307841
Iteration 100 loss 0.447667503548 train RMSE 0.983125317253 Validation RMSE 100 : 0.841624408234
Iteration 110 loss 0.421016419906 train RMSE 0.963487730149 Validation RMSE 110 : 0.870366019173
Iteration 120 loss 0.416460578337 train RMSE 0.937120042735 Validation RMSE 120 : 0.734118599467
Iteration 130 loss 0.422747733604 train RMSE 0.946051411268 Validation RMSE 130 : 0.682651829966
Iteration 140 loss 0.437336635743 train RMSE 1.02859560043 Validation RMSE 140 : 0.898832914165
Iteration 150 loss 0.441332734999 train RMSE 0.946131957942 Validation RMSE 150 : 0.700921632959
Iteration 160 loss 0.44856865324 train RMSE 0.960772616499 Validation RMSE 160 : 0.718278647404
Iteration 170 loss 0.43941012702 train RMSE 1.02122940762 Validation RMSE 170 : 0.670649564245
Iteration 180 loss 0.455848238694 train RMSE 0.981731528685 Validation RMSE 180 : 0.731950939093
Iteration 190 loss 0.455469380766 train RMSE 0.981162323649 Validation RMSE 190 : 0.706128634937
Iteration 200 loss 0.459662840964 train RMSE 0.99769296362 Validation RMSE 200 : 0.67372440148
Iteration 210 loss 0.45436797172 train RMSE 1.02209022892 Validation RMSE 210 : 0.779579054146
Iteration 220 loss 0.461357265008 train RMSE 1.0034881196 Validation RMSE 220 : 0.706195210551
Iteration 230 loss 0.466864672729 train RMSE 1.02638129924 Validation RMSE 230 : 0.785081053212
Iteration 240 loss 0.469249475129 train RMSE 1.00449772492 Validation RMSE 240 : 0.657454293914
Iteration 250 loss 0.48412750443 train RMSE 1.00932429278 Validation RMSE 250 : 0.636741076119
Iteration 260 loss 0.484787104251 train RMSE 1.02687357888 Validation RMSE 260 : 0.607719054308
Iteration 270 loss 0.483348774526 train RMSE 1.03060025641 Validation RMSE 270 : 0.684642815118
Iteration 280 loss 0.47323383949 train RMSE 1.02618563396 Validation RMSE 280 : 0.69811146186
Iteration 290 loss 0.472254621884 train RMSE 1.01689936575 Validation RMSE 290 : 0.668271224933
Iteration 300 loss 0.498920825778 train RMSE 1.049987777 Validation RMSE 300 : 0.730824348267
Iteration 310 loss 0.47649958461 train RMSE 1.04625062685 Validation RMSE 310 : 0.710239864585
Iteration 320 loss 0.474736812735 train RMSE 1.04867239991 Validation RMSE 320 : 0.724794595494
Iteration 330 loss 0.479386063464 train RMSE 1.04515646324 Validation RMSE 330 : 0.720188525737
Iteration 340 loss 0.479856566292 train RMSE 1.04653532296 Validation RMSE 340 : 0.708120276628
Iteration 350 loss 0.483818318819 train RMSE 1.05686116341 Validation RMSE 350 : 0.74228904431
Iteration 360 loss 0.478552151279 train RMSE 1.05471942995 Validation RMSE 360 : 0.741961876556
Iteration 370 loss 0.482009572511 train RMSE 1.05610702495 Validation RMSE 370 : 0.73576560149
Iteration 380 loss 0.481967171192 train RMSE 1.05942218642 Validation RMSE 380 : 0.757065670463
Iteration 390 loss 0.483905564758 train RMSE 1.0621234002 Validation RMSE 390 : 0.754948542843
Iteration 400 loss 0.485016720744 train RMSE 1.06490138703 Validation RMSE 400 : 0.774081568878
Iteration 410 loss 0.485826425032 train RMSE 1.07564436209 Validation RMSE 410 : 0.831125222787
Iteration 420 loss 0.481910650911 train RMSE 1.07090258517 Validation RMSE 420 : 0.792553308962
Iteration 430 loss 0.484021042119 train RMSE 1.0726947308 Validation RMSE 430 : 0.7980424893
Iteration 440 loss 0.484816319399 train RMSE 1.07361899539 Validation RMSE 440 : 0.79858588764
Iteration 450 loss 0.485990659989 train RMSE 1.07731852568 Validation RMSE 450 : 0.813602506452
Iteration 460 loss 0.487622205383 train RMSE 1.07704750065 Validation RMSE 460 : 0.802753680292
Iteration 470 loss 0.483859510841 train RMSE 1.08011929259 Validation RMSE 470 : 0.820661888194
Iteration 480 loss 0.487261508412 train RMSE 1.08242939258 Validation RMSE 480 : 0.824533953667
Iteration 490 loss 0.48644253714 train RMSE 1.08755701727 Validation RMSE 490 : 0.850384799024
Iteration 500 loss 0.492806650706 train RMSE 1.08260057806 Validation RMSE 500 : 0.826100483869
Iteration 510 loss 0.486197886972 train RMSE 1.08494500561 Validation RMSE 510 : 0.821216557372
Iteration 520 loss 0.488219707425 train RMSE 1.08506751031 Validation RMSE 520 : 0.823438012487
Iteration 530 loss 0.486450179996 train RMSE 1.08340999748 Validation RMSE 530 : 0.79895428918
Iteration 540 loss 0.491867915348 train RMSE 1.08649304128 Validation RMSE 540 : 0.834301890338
Iteration 550 loss 0.486816390945 train RMSE 1.09096412086 Validation RMSE 550 : 0.854994725272
Iteration 560 loss 0.487362646047 train RMSE 1.09289926413 Validation RMSE 560 : 0.865343280767
Iteration 570 loss 0.491862931788 train RMSE 1.0854921045 Validation RMSE 570 : 0.822505924876
Iteration 580 loss 0.487728706533 train RMSE 1.08625832628 Validation RMSE 580 : 0.823278894658
Iteration 590 loss 0.487188734429 train RMSE 1.0857611863 Validation RMSE 590 : 0.808087508356
Iteration 600 loss 0.486191236235 train RMSE 1.08846521185 Validation RMSE 600 : 0.847639408911
Iteration 610 loss 0.487178029206 train RMSE 1.08743660183 Validation RMSE 610 : 0.82448378365
Iteration 620 loss 0.486744040235 train RMSE 1.08953853148 Validation RMSE 620 : 0.842381603966
Iteration 630 loss 0.486480780852 train RMSE 1.08939376894 Validation RMSE 630 : 0.837090597151
Iteration 640 loss 0.486132218455 train RMSE 1.08938742214 Validation RMSE 640 : 0.834097646842
Iteration 650 loss 0.485947624788 train RMSE 1.08898739002 Validation RMSE 650 : 0.828201182478
Iteration 660 loss 0.485554044614 train RMSE 1.08878846846 Validation RMSE 660 : 0.822976065959
Iteration 670 loss 0.485477116577 train RMSE 1.08879202682 Validation RMSE 670 : 0.820457917903
Iteration 680 loss 0.485348123887 train RMSE 1.08921719387 Validation RMSE 680 : 0.824316516158
Iteration 690 loss 0.485289172455 train RMSE 1.08902055832 Validation RMSE 690 : 0.820213602553
Iteration 700 loss 0.485246443542 train RMSE 1.08895794272 Validation RMSE 700 : 0.818696091603
Iteration 710 loss 0.485362169852 train RMSE 1.08902635993 Validation RMSE 710 : 0.818376636551
Iteration 720 loss 0.485821670882 train RMSE 1.08896325205 Validation RMSE 720 : 0.818749601058
Iteration 730 loss 0.485695086053 train RMSE 1.08903259937 Validation RMSE 730 : 0.81931451308
Iteration 740 loss 0.484750494463 train RMSE 1.08995553267 Validation RMSE 740 : 0.820202411349
Iteration 750 loss 0.484865755227 train RMSE 1.08986398548 Validation RMSE 750 : 0.817012579962
Iteration 760 loss 0.485573976701 train RMSE 1.08886362939 Validation RMSE 760 : 0.813108289871
Iteration 770 loss 0.484935866471 train RMSE 1.08929719517 Validation RMSE 770 : 0.814705715759
Iteration 780 loss 0.484465836652 train RMSE 1.08973928518 Validation RMSE 780 : 0.813105650898
Iteration 790 loss 0.484885700242 train RMSE 1.0892818739 Validation RMSE 790 : 0.809779564627
Iteration 800 loss 0.485302774905 train RMSE 1.08856038103 Validation RMSE 800 : 0.806939760028
Iteration 810 loss 0.484315714746 train RMSE 1.08948798167 Validation RMSE 810 : 0.809772903255
Iteration 820 loss 0.48436494017 train RMSE 1.08936110443 Validation RMSE 820 : 0.805873478347
Iteration 830 loss 0.484972969241 train RMSE 1.08863473643 Validation RMSE 830 : 0.802853058072
Iteration 840 loss 0.484468958571 train RMSE 1.0888937361 Validation RMSE 840 : 0.804101156291
Iteration 850 loss 0.48408284144 train RMSE 1.08921068188 Validation RMSE 850 : 0.802706975539
Iteration 860 loss 0.484449165573 train RMSE 1.08878704512 Validation RMSE 860 : 0.799200218486
Iteration 870 loss 0.484588529836 train RMSE 1.08846723798 Validation RMSE 870 : 0.798055298285
Iteration 880 loss 0.484016254844 train RMSE 1.08888568948 Validation RMSE 880 : 0.798988755172
Iteration 890 loss 0.484062432375 train RMSE 1.0887575924 Validation RMSE 890 : 0.795941834934
Iteration 900 loss 0.484320868267 train RMSE 1.08843383377 Validation RMSE 900 : 0.793834382926
Iteration 910 loss 0.484105281183 train RMSE 1.08847638289 Validation RMSE 910 : 0.793952519571
Iteration 920 loss 0.483872722342 train RMSE 1.08858770367 Validation RMSE 920 : 0.792993704868
Iteration 930 loss 0.483961405605 train RMSE 1.08842835757 Validation RMSE 930 : 0.790539671323
Iteration 940 loss 0.484015392821 train RMSE 1.08829368918 Validation RMSE 940 : 0.789190678525
Iteration 950 loss 0.48387723388 train RMSE 1.08830108296 Validation RMSE 950 : 0.788720349451
Iteration 960 loss 0.483765033469 train RMSE 1.08830152111 Validation RMSE 960 : 0.787552625926
Iteration 970 loss 0.483761814599 train RMSE 1.08822451387 Validation RMSE 970 : 0.785740876677
Iteration 980 loss 0.483761984014 train RMSE 1.08815549848 Validation RMSE 980 : 0.784135183019
Iteration 990 loss 0.483727098731 train RMSE 1.08811616871 Validation RMSE 990 : 0.782803516755

Neural test RMSE 1.2367729845

real	56m5.759s
user	66m20.677s
sys	66m49.306s

Neural test RMSE 1.21992074537
Neural test RMSE 1.225

