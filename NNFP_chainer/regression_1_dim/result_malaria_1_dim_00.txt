Loading data...
Starting neural fingerprint experiment...
Iteration 0 loss 1.03088505385 train RMSE 2.37150829029 Validation RMSE 0 : 3.62657815189
Iteration 10 loss 0.939202035195 train RMSE 2.09016156498 Validation RMSE 10 : 3.46183059226
Iteration 20 loss 0.868531431518 train RMSE 1.95193384087 Validation RMSE 20 : 3.16054929498
Iteration 30 loss 0.825004998105 train RMSE 1.88377653269 Validation RMSE 30 : 3.07206555665
Iteration 40 loss 0.80785103564 train RMSE 1.83360863555 Validation RMSE 40 : 3.07472126015
Iteration 50 loss 0.807403683838 train RMSE 1.81160009998 Validation RMSE 50 : 3.06223996674
Iteration 60 loss 0.817529954507 train RMSE 1.93214069061 Validation RMSE 60 : 3.01399669269
Iteration 70 loss 0.808950483716 train RMSE 1.81427480686 Validation RMSE 70 : 2.94365858191
Iteration 80 loss 0.816368722738 train RMSE 1.81720838986 Validation RMSE 80 : 2.93456251299
Iteration 90 loss 0.80656506644 train RMSE 1.81218341825 Validation RMSE 90 : 2.83027188077
Iteration 100 loss 0.843227047807 train RMSE 1.87683587795 Validation RMSE 100 : 2.88574697943
Iteration 110 loss 0.866472654146 train RMSE 1.83073141678 Validation RMSE 110 : 2.80753158837
Iteration 120 loss 0.848465107281 train RMSE 1.92513587769 Validation RMSE 120 : 2.9306108571
Iteration 130 loss 0.845405861146 train RMSE 1.90455833792 Validation RMSE 130 : 2.80702031699
Iteration 140 loss 0.876231144853 train RMSE 1.87997488614 Validation RMSE 140 : 2.84153543954
Iteration 150 loss 0.919008972363 train RMSE 2.02427049377 Validation RMSE 150 : 2.9993185223
Iteration 160 loss 0.902755115094 train RMSE 1.99859056878 Validation RMSE 160 : 2.91628411827
Iteration 170 loss 0.903106796187 train RMSE 2.0134262986 Validation RMSE 170 : 3.01428002917
Iteration 180 loss 0.925271807507 train RMSE 2.01412730797 Validation RMSE 180 : 2.99241473976
Iteration 190 loss 0.915384298721 train RMSE 2.01545158646 Validation RMSE 190 : 2.93188329171
Iteration 200 loss 0.925288878258 train RMSE 2.17424705013 Validation RMSE 200 : 3.18522742545
Iteration 210 loss 0.953065338769 train RMSE 2.05640655664 Validation RMSE 210 : 2.90326463509
Iteration 220 loss 0.957597930671 train RMSE 2.01718812406 Validation RMSE 220 : 2.9183043832
Iteration 230 loss 0.924474220084 train RMSE 2.04673242436 Validation RMSE 230 : 2.93655412745
Iteration 240 loss 0.936350912963 train RMSE 2.09983465361 Validation RMSE 240 : 3.00893533729
Iteration 250 loss 0.938355087691 train RMSE 2.12473093461 Validation RMSE 250 : 3.04354410278
Iteration 260 loss 0.945792399514 train RMSE 2.14138568811 Validation RMSE 260 : 3.20505104774
Iteration 270 loss 0.944483622193 train RMSE 2.16950310375 Validation RMSE 270 : 3.23135190467
Iteration 280 loss 0.946601902572 train RMSE 2.11885326213 Validation RMSE 280 : 3.00414657128
Iteration 290 loss 0.944969808712 train RMSE 2.17737152772 Validation RMSE 290 : 3.17855267343
Iteration 300 loss 0.952437512458 train RMSE 2.17913942727 Validation RMSE 300 : 3.11854986187
Iteration 310 loss 0.95518539856 train RMSE 2.19951772606 Validation RMSE 310 : 3.21560574629
Iteration 320 loss 1.03816534333 train RMSE 2.20429225869 Validation RMSE 320 : 3.22419707483
Iteration 330 loss 0.952424151287 train RMSE 2.20513034755 Validation RMSE 330 : 3.14383044282
Iteration 340 loss 0.954005538185 train RMSE 2.20743037303 Validation RMSE 340 : 3.16996143667
Iteration 350 loss 0.952277541578 train RMSE 2.21537298106 Validation RMSE 350 : 3.20923192375
Iteration 360 loss 0.958091117822 train RMSE 2.2166857721 Validation RMSE 360 : 3.19214545926
Iteration 370 loss 0.961367286154 train RMSE 2.22634297677 Validation RMSE 370 : 3.19474507636
Iteration 380 loss 0.954458648174 train RMSE 2.22426350009 Validation RMSE 380 : 3.20598894808
Iteration 390 loss 0.957077492356 train RMSE 2.22681455022 Validation RMSE 390 : 3.19280489619
Iteration 400 loss 0.957360845369 train RMSE 2.22914172245 Validation RMSE 400 : 3.19481821131
Iteration 410 loss 0.955499661336 train RMSE 2.23159029634 Validation RMSE 410 : 3.19718315004
Iteration 420 loss 0.95651330751 train RMSE 2.23210263243 Validation RMSE 420 : 3.20423148048
Iteration 430 loss 0.956961368423 train RMSE 2.23316837622 Validation RMSE 430 : 3.19999281167
Iteration 440 loss 0.956488256754 train RMSE 2.23546632378 Validation RMSE 440 : 3.19618627265
Iteration 450 loss 0.956570572817 train RMSE 2.238287002 Validation RMSE 450 : 3.19808056605
Iteration 460 loss 0.956895810878 train RMSE 2.23906168222 Validation RMSE 460 : 3.20275683264
Iteration 470 loss 0.957340517482 train RMSE 2.23894912848 Validation RMSE 470 : 3.20166488491
Iteration 480 loss 0.957141978806 train RMSE 2.23979362269 Validation RMSE 480 : 3.19924885755
Iteration 490 loss 0.95696628895 train RMSE 2.24091592813 Validation RMSE 490 : 3.19764053859
Iteration 500 loss 0.9569351148 train RMSE 2.24207606022 Validation RMSE 500 : 3.19760668782
Iteration 510 loss 0.956971271737 train RMSE 2.24284284099 Validation RMSE 510 : 3.19856212617
Iteration 520 loss 0.957044235453 train RMSE 2.24320763964 Validation RMSE 520 : 3.19927628201
Iteration 530 loss 0.957110841517 train RMSE 2.24340298235 Validation RMSE 530 : 3.19944469879
Iteration 540 loss 0.957137619647 train RMSE 2.24359469501 Validation RMSE 540 : 3.19932188955
Iteration 550 loss 0.95712899468 train RMSE 2.24380009842 Validation RMSE 550 : 3.19916360176
Iteration 560 loss 0.957108817558 train RMSE 2.24399549581 Validation RMSE 560 : 3.19909682641
Iteration 570 loss 0.957082474564 train RMSE 2.24415974821 Validation RMSE 570 : 3.19909190764
Iteration 580 loss 0.957049466952 train RMSE 2.24429243751 Validation RMSE 580 : 3.19906790987
Iteration 590 loss 0.957015212567 train RMSE 2.24439941189 Validation RMSE 590 : 3.19904048362
Iteration 600 loss 0.95699054865 train RMSE 2.24448109991 Validation RMSE 600 : 3.19905628355
Iteration 610 loss 0.956978621301 train RMSE 2.24454313408 Validation RMSE 610 : 3.19921740857
Iteration 620 loss 0.95696666266 train RMSE 2.24458870262 Validation RMSE 620 : 3.1994855348
Iteration 630 loss 0.956951122433 train RMSE 2.24462386092 Validation RMSE 630 : 3.19981697274
Iteration 640 loss 0.956931066135 train RMSE 2.24465477003 Validation RMSE 640 : 3.20012423751
Iteration 650 loss 0.956906275472 train RMSE 2.24467537587 Validation RMSE 650 : 3.20045054363
Iteration 660 loss 0.956886373959 train RMSE 2.24468971487 Validation RMSE 660 : 3.20077666752
Iteration 670 loss 0.956861270679 train RMSE 2.24470309786 Validation RMSE 670 : 3.20112063336
Iteration 680 loss 0.956840060074 train RMSE 2.24471244466 Validation RMSE 680 : 3.20145428513
Iteration 690 loss 0.956811529356 train RMSE 2.24471297572 Validation RMSE 690 : 3.20180130566
Iteration 700 loss 0.956791906206 train RMSE 2.24471616212 Validation RMSE 700 : 3.2021561809
Iteration 710 loss 0.956765679083 train RMSE 2.24471255087 Validation RMSE 710 : 3.20251890822
Iteration 720 loss 0.956743812214 train RMSE 2.24470384135 Validation RMSE 720 : 3.20289365352
Iteration 730 loss 0.95672225635 train RMSE 2.2446929013 Validation RMSE 730 : 3.2032961916
Iteration 740 loss 0.956701603383 train RMSE 2.24466836566 Validation RMSE 740 : 3.20371520025
Iteration 750 loss 0.956686121154 train RMSE 2.24462587905 Validation RMSE 750 : 3.20416481074
Iteration 760 loss 0.956675996824 train RMSE 2.24455152556 Validation RMSE 760 : 3.20466777585
Iteration 770 loss 0.956688924795 train RMSE 2.24443159881 Validation RMSE 770 : 3.20535319913
Iteration 780 loss 0.956558982945 train RMSE 2.24441173433 Validation RMSE 780 : 3.20721516796
Iteration 790 loss 0.956824922703 train RMSE 2.24426736631 Validation RMSE 790 : 3.20703690002
Iteration 800 loss 0.957614923109 train RMSE 2.24410184689 Validation RMSE 800 : 3.20833970767
Iteration 810 loss 0.958497088719 train RMSE 2.24429105648 Validation RMSE 810 : 3.20841104653
Iteration 820 loss 0.956507231827 train RMSE 2.24511697511 Validation RMSE 820 : 3.20906580371
Iteration 830 loss 0.956405123427 train RMSE 2.24498709575 Validation RMSE 830 : 3.21767755808
Iteration 840 loss 0.957150821612 train RMSE 2.24431867698 Validation RMSE 840 : 3.21654353392
Iteration 850 loss 0.957996893304 train RMSE 2.24404150044 Validation RMSE 850 : 3.21406970434
Iteration 860 loss 0.956158921635 train RMSE 2.24412097042 Validation RMSE 860 : 3.20990582527
Iteration 870 loss 0.955733902978 train RMSE 2.2457278277 Validation RMSE 870 : 3.21955431916
Iteration 880 loss 0.955760626141 train RMSE 2.24653114372 Validation RMSE 880 : 3.22561949465
Iteration 890 loss 0.957086678282 train RMSE 2.24427894584 Validation RMSE 890 : 3.22056543207
Iteration 900 loss 0.956694781265 train RMSE 2.24403714439 Validation RMSE 900 : 3.21431686144
Iteration 910 loss 0.955815036807 train RMSE 2.24420309353 Validation RMSE 910 : 3.2149609235
Iteration 920 loss 0.955551311079 train RMSE 2.24602050662 Validation RMSE 920 : 3.22418849701
Iteration 930 loss 0.956088415219 train RMSE 2.24593484068 Validation RMSE 930 : 3.22949573112
Iteration 940 loss 0.957324547492 train RMSE 2.24405148747 Validation RMSE 940 : 3.21929482599
Iteration 950 loss 0.955651015881 train RMSE 2.24404277538 Validation RMSE 950 : 3.21810314012
Iteration 960 loss 0.955430104432 train RMSE 2.24594205925 Validation RMSE 960 : 3.22787382436
Iteration 970 loss 0.95571809324 train RMSE 2.24587804671 Validation RMSE 970 : 3.23369720286
Iteration 980 loss 0.956475014485 train RMSE 2.24413297567 Validation RMSE 980 : 3.22753463029
Iteration 990 loss 0.955912064073 train RMSE 2.24402906972 Validation RMSE 990 : 3.22432884507

Neural test RMSE 2.26083119425

real	118m18.957s
user	117m0.622s
sys	61m26.002s

