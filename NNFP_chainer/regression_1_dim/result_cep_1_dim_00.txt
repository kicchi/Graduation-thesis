Loading data...
Starting neural fingerprint experiment...
Iteration 0 loss 1.31136804542 train RMSE 2.6959804426 Validation RMSE 0 : 3.42097886427
Iteration 10 loss 0.853595860811 train RMSE 2.15038308568 Validation RMSE 10 : 3.39792350302
Iteration 20 loss 0.773727593783 train RMSE 2.04893250468 Validation RMSE 20 : 3.28614224437
Iteration 30 loss 0.702659707293 train RMSE 1.87309556247 Validation RMSE 30 : 2.75253716384
Iteration 40 loss 0.704389621681 train RMSE 1.81992496409 Validation RMSE 40 : 2.83488676084
Iteration 50 loss 0.696128216713 train RMSE 1.8124602741 Validation RMSE 50 : 2.78351123911
Iteration 60 loss 0.72976887676 train RMSE 1.90714949351 Validation RMSE 60 : 2.84481925565
Iteration 70 loss 0.704921102607 train RMSE 1.85602370145 Validation RMSE 70 : 2.74328791175
Iteration 80 loss 0.69803958968 train RMSE 1.84350215733 Validation RMSE 80 : 2.71567176981
Iteration 90 loss 0.710808291589 train RMSE 1.84787147349 Validation RMSE 90 : 2.77931926448
Iteration 100 loss 0.787620965053 train RMSE 1.85130533613 Validation RMSE 100 : 2.75763111761
Iteration 110 loss 0.725599039814 train RMSE 1.87726386413 Validation RMSE 110 : 2.72069874343
Iteration 120 loss 0.724078824745 train RMSE 1.88715700229 Validation RMSE 120 : 2.75478934339
Iteration 130 loss 0.773447749523 train RMSE 1.9275983861 Validation RMSE 130 : 2.80726441398
Iteration 140 loss 0.791831944597 train RMSE 1.9377110274 Validation RMSE 140 : 2.8197373414
Iteration 150 loss 0.786350385992 train RMSE 1.98551877918 Validation RMSE 150 : 2.83921586642
Iteration 160 loss 0.806471171834 train RMSE 2.03083468373 Validation RMSE 160 : 2.79889831668
Iteration 170 loss 0.779393508006 train RMSE 1.98313612826 Validation RMSE 170 : 2.80903445886
Iteration 180 loss 0.853060218951 train RMSE 2.07021725993 Validation RMSE 180 : 3.07196792353
Iteration 190 loss 0.81548363056 train RMSE 2.04129771058 Validation RMSE 190 : 2.80721124783
Iteration 200 loss 0.884960666741 train RMSE 2.1777134642 Validation RMSE 200 : 3.2084045072
Iteration 210 loss 0.852446560905 train RMSE 2.09511737868 Validation RMSE 210 : 2.94102201954
Iteration 220 loss 0.841886900582 train RMSE 2.04079518565 Validation RMSE 220 : 2.83205094955
Iteration 230 loss 0.832880187013 train RMSE 2.0425762434 Validation RMSE 230 : 2.9713881165
Iteration 240 loss 0.921369640392 train RMSE 2.10916215741 Validation RMSE 240 : 3.01587687809
Iteration 250 loss 0.849560159595 train RMSE 2.06192736913 Validation RMSE 250 : 2.90326857689
Iteration 260 loss 0.846842221122 train RMSE 2.06067530517 Validation RMSE 260 : 2.95283918663
Iteration 270 loss 0.895154810628 train RMSE 2.15440101406 Validation RMSE 270 : 3.1455182724
Iteration 280 loss 0.902534134502 train RMSE 2.15429598963 Validation RMSE 280 : 3.09278469246
Iteration 290 loss 0.902316865066 train RMSE 2.16165456839 Validation RMSE 290 : 3.13629672013
Iteration 300 loss 0.882496363657 train RMSE 2.13808942554 Validation RMSE 300 : 3.00184733416
Iteration 310 loss 0.926558992788 train RMSE 2.20386984929 Validation RMSE 310 : 3.25095206767
Iteration 320 loss 0.917337630818 train RMSE 2.19714268319 Validation RMSE 320 : 3.15450351853
Iteration 330 loss 0.912332772909 train RMSE 2.19284309704 Validation RMSE 330 : 3.0919635894
Iteration 340 loss 0.922553863142 train RMSE 2.19561005337 Validation RMSE 340 : 3.19623669827
Iteration 350 loss 0.906864484099 train RMSE 2.18279086452 Validation RMSE 350 : 3.11623863368
Iteration 360 loss 0.92781776455 train RMSE 2.21635608744 Validation RMSE 360 : 3.13517584568
Iteration 370 loss 0.928187466456 train RMSE 2.21932223825 Validation RMSE 370 : 3.13674094452
Iteration 380 loss 0.927521819812 train RMSE 2.22413304616 Validation RMSE 380 : 3.16185964502
Iteration 390 loss 0.930637002974 train RMSE 2.22504542015 Validation RMSE 390 : 3.14132257562
Iteration 400 loss 0.930647122368 train RMSE 2.22614742225 Validation RMSE 400 : 3.16241683549
Iteration 410 loss 0.933221655079 train RMSE 2.22802493605 Validation RMSE 410 : 3.1519558844
Iteration 420 loss 0.933795412382 train RMSE 2.23168046576 Validation RMSE 420 : 3.16936073813
Iteration 430 loss 0.937635761604 train RMSE 2.23175588905 Validation RMSE 430 : 3.14603576683
Iteration 440 loss 0.936057124828 train RMSE 2.23449535979 Validation RMSE 440 : 3.16723142574
Iteration 450 loss 0.937516434843 train RMSE 2.23569326926 Validation RMSE 450 : 3.16365210615
Iteration 460 loss 0.938742005661 train RMSE 2.23757289576 Validation RMSE 460 : 3.17023309013
Iteration 470 loss 0.93937229118 train RMSE 2.23876702861 Validation RMSE 470 : 3.17230898139
Iteration 480 loss 0.939954152207 train RMSE 2.23993583093 Validation RMSE 480 : 3.1750439378
Iteration 490 loss 0.940425441015 train RMSE 2.24088315873 Validation RMSE 490 : 3.17711818655
Iteration 500 loss 0.940797125951 train RMSE 2.24167736245 Validation RMSE 500 : 3.17898589321
Iteration 510 loss 0.941096464606 train RMSE 2.24232434643 Validation RMSE 510 : 3.18054547556
Iteration 520 loss 0.94133789954 train RMSE 2.24284698677 Validation RMSE 520 : 3.18184174616
Iteration 530 loss 0.941575252828 train RMSE 2.24326173788 Validation RMSE 530 : 3.18311711587
Iteration 540 loss 0.9417662506 train RMSE 2.24361871107 Validation RMSE 540 : 3.18444677989
Iteration 550 loss 0.94190462462 train RMSE 2.24389742736 Validation RMSE 550 : 3.18558609293
Iteration 560 loss 0.942005900379 train RMSE 2.24411735821 Validation RMSE 560 : 3.18660858256
Iteration 570 loss 0.942085559195 train RMSE 2.24429222505 Validation RMSE 570 : 3.18757210444
Iteration 580 loss 0.942143005535 train RMSE 2.24442586256 Validation RMSE 580 : 3.18848000215
Iteration 590 loss 0.942176029268 train RMSE 2.24453251192 Validation RMSE 590 : 3.1893463771
Iteration 600 loss 0.942187796066 train RMSE 2.24461238939 Validation RMSE 600 : 3.19017769035
Iteration 610 loss 0.942171474339 train RMSE 2.24467197698 Validation RMSE 610 : 3.19098831484
Iteration 620 loss 0.942206363268 train RMSE 2.24472126035 Validation RMSE 620 : 3.19247691242
Iteration 630 loss 0.94243910231 train RMSE 2.24476066503 Validation RMSE 630 : 3.1960260392
Iteration 640 loss 0.942563560427 train RMSE 2.24479847588 Validation RMSE 640 : 3.19861221619
Iteration 650 loss 0.942632612415 train RMSE 2.24482364735 Validation RMSE 650 : 3.20060772489
Iteration 660 loss 0.942681710867 train RMSE 2.24485349164 Validation RMSE 660 : 3.20249493613
Iteration 670 loss 0.94270949952 train RMSE 2.24487823768 Validation RMSE 670 : 3.20417314454
Iteration 680 loss 0.942723377733 train RMSE 2.24489947869 Validation RMSE 680 : 3.20564476086
Iteration 690 loss 0.942727898382 train RMSE 2.2449175334 Validation RMSE 690 : 3.2069936325
Iteration 700 loss 0.942727424189 train RMSE 2.24493388871 Validation RMSE 700 : 3.20821337455
Iteration 710 loss 0.942724737091 train RMSE 2.24494886327 Validation RMSE 710 : 3.20936475416
Iteration 720 loss 0.942715664127 train RMSE 2.24496065169 Validation RMSE 720 : 3.2104282393
Iteration 730 loss 0.942701216753 train RMSE 2.24497095323 Validation RMSE 730 : 3.21142856528
Iteration 740 loss 0.942681679252 train RMSE 2.24498231673 Validation RMSE 740 : 3.21237083799
Iteration 750 loss 0.942654237547 train RMSE 2.24499261817 Validation RMSE 750 : 3.21326401231
Iteration 760 loss 0.942611461039 train RMSE 2.24499718477 Validation RMSE 760 : 3.2140763805
Iteration 770 loss 0.942608583909 train RMSE 2.24499134376 Validation RMSE 770 : 3.21484968294
Iteration 780 loss 0.942673617544 train RMSE 2.24499431737 Validation RMSE 780 : 3.21571725726
Iteration 790 loss 0.94269868765 train RMSE 2.24501045972 Validation RMSE 790 : 3.21661113302
Iteration 800 loss 0.942698845719 train RMSE 2.24501863706 Validation RMSE 800 : 3.21743895857
Iteration 810 loss 0.942694704298 train RMSE 2.24502405319 Validation RMSE 810 : 3.21822345464
Iteration 820 loss 0.942687622742 train RMSE 2.2450310623 Validation RMSE 820 : 3.21895620926
Iteration 830 loss 0.94267756937 train RMSE 2.24503488543 Validation RMSE 830 : 3.21967783768
Iteration 840 loss 0.942668780486 train RMSE 2.24504285028 Validation RMSE 840 : 3.22037472505
Iteration 850 loss 0.94266018121 train RMSE 2.24504614241 Validation RMSE 850 : 3.22109070638
Iteration 860 loss 0.942647661536 train RMSE 2.24505007172 Validation RMSE 860 : 3.22172482989
Iteration 870 loss 0.942640231853 train RMSE 2.24505559398 Validation RMSE 870 : 3.2223915315
Iteration 880 loss 0.942628944946 train RMSE 2.24505973567 Validation RMSE 880 : 3.22302258808
Iteration 890 loss 0.942614116843 train RMSE 2.2450654703 Validation RMSE 890 : 3.22364538561
Iteration 900 loss 0.942603525198 train RMSE 2.24507003675 Validation RMSE 900 : 3.22424721027
Iteration 910 loss 0.942591479033 train RMSE 2.24507577135 Validation RMSE 910 : 3.22484729612
Iteration 920 loss 0.942576681959 train RMSE 2.24508150594 Validation RMSE 920 : 3.22540365842
Iteration 930 loss 0.942561441994 train RMSE 2.2450852228 Validation RMSE 930 : 3.22597056725
Iteration 940 loss 0.942545790736 train RMSE 2.24509170073 Validation RMSE 940 : 3.22647826152
Iteration 950 loss 0.942531467236 train RMSE 2.24509849723 Validation RMSE 950 : 3.22700759736
Iteration 960 loss 0.942512748339 train RMSE 2.24510370079 Validation RMSE 960 : 3.22749163756
Iteration 970 loss 0.942494092311 train RMSE 2.24511039106 Validation RMSE 970 : 3.22796290121
Iteration 980 loss 0.942473538632 train RMSE 2.24511676272 Validation RMSE 980 : 3.22840544229
Iteration 990 loss 0.942450486357 train RMSE 2.24512409012 Validation RMSE 990 : 3.22882562293

Neural test RMSE 2.23975487577

real	163m53.224s
user	141m31.296s
sys	59m59.265s

Neural test RMSE 2.25767606435
Neural test RMSE 2.245920085

